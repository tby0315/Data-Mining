{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d6148a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['help', 'choice', 'string', 'number', 'point', 'helppct-up', 'recent8help', 'asymptoteA-up', 'asymptoteB-up']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df1 = pd.read_csv(\"ca1-dataset.csv\")\n",
    "df2 = pd.read_csv(\"ca2-dataset.csv\")\n",
    "\n",
    "#find no variance data in ca2\n",
    "cols_with_zero = [col for col in df2.columns if df2[col].nunique() == 1]\n",
    "\n",
    "print(cols_with_zero)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30184b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#find no variance data in ca1\n",
    "cols_with_zero_1 = [col for col in df1.columns if df1[col].nunique() == 1]\n",
    "\n",
    "print(cols_with_zero_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc4d418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          pknow-1   Pknow-2   pchange\n",
      "pknow-1  1.000000  0.424843 -0.981923\n",
      "Pknow-2  0.424843  1.000000 -0.305216\n",
      "pchange -0.981923 -0.305216  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Selecting the  Pknow-1 &2 & Pchange and calculating correlation\n",
    "selected_cols = df2[['pknow-1','Pknow-2','pchange']]\n",
    "correlation_matrix = selected_cols.corr()\n",
    "\n",
    "print(correlation_matrix)\n",
    "\n",
    "# print(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b06b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 howmanywrong-up  wrongpct-up\n",
      "howmanywrong-up         1.000000     0.553766\n",
      "wrongpct-up             0.553766     1.000000\n"
     ]
    }
   ],
   "source": [
    "# Selecting the  howmanywrong-up & wrongpct-up and calculating correlation\n",
    "selected_cols = df2[['howmanywrong-up','wrongpct-up']]\n",
    "correlation = selected_cols.corr()\n",
    "\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5358cc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   timeSDnormed  timelast3SDnormed  timelast5SDnormed\n",
      "timeSDnormed           1.000000           0.096334           0.107049\n",
      "timelast3SDnormed      0.096334           1.000000           0.855967\n",
      "timelast5SDnormed      0.107049           0.855967           1.000000\n"
     ]
    }
   ],
   "source": [
    "# Selecting the  timeSDnormed','timelast3SDnormed','timelast5SDnormed and calculating correlation\n",
    "selected_cols = df2[['timeSDnormed','timelast3SDnormed','timelast5SDnormed']]\n",
    "correlation = selected_cols.corr()\n",
    "\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56cc9493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Prev3Count-up  Prev5Count-up\n",
      "Prev3Count-up       1.000000       0.956364\n",
      "Prev5Count-up       0.956364       1.000000\n"
     ]
    }
   ],
   "source": [
    "# Selecting the  'Prev3Count-up'&'Prev5Count-up'and calculating correlation\n",
    "selected_cols = df2[['Prev3Count-up','Prev5Count-up']]\n",
    "correlation = selected_cols.corr()\n",
    "\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c74a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get Dummy categorical columns\n",
    "dummies = pd.get_dummies(df2[['prod', 'cell']], prefix=['dummy_prod', 'dummy_cell'])\n",
    "# Add the 'ID' column to the dummy DataFrame for merging\n",
    "dummies['Unique-id'] = df2['Unique-id']\n",
    "\n",
    "# Merging 'pknow-1'& 'Pknow-2' into ca1 using Unique-id\n",
    "merged_p = pd.merge(df1,df2[['Unique-id', 'pknow-1', 'Pknow-2']], on='Unique-id', how='left')\n",
    "\n",
    "# Merging 'dummy_prod', 'dummy_cell' into ca1 using Unique-id\n",
    "merged1 = pd.merge(merged_p,dummies, on='Unique-id', how='left')\n",
    "\n",
    "\n",
    "# print(merged_dummy)\n",
    "# print(ca1_merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bef756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature5: Calculate the total number of steps\n",
    "df2['totalstep'] = np.where(df2['wrongpct-up'] == 0, \n",
    "                            0, \n",
    "                            (df2['howmanywrong-up'] / df2['wrongpct-up']))\n",
    "merged5 = pd.merge(merged1,df2[['totalstep','Unique-id']], on='Unique-id', how='left')\n",
    "\n",
    "# Feature6: Calculate The total number of actions\n",
    "df2['totalaction'] = np.where(df2['timeperact-up'] == 0, \n",
    "                            0, \n",
    "                            (df2['time'] / df2['timeperact-up']))\n",
    "# merged6 = pd.merge(merged5,df2[['totalaction','Unique-id']], on='Unique-id', how='left')\n",
    "\n",
    "# Feature7\n",
    "df2['last5'] = df2['Prev5Count-up']*df2['timelast5SDnormed']\n",
    "# merged7 = pd.merge(merged6,df2[['last5','Unique-id']], on='Unique-id', how='left')\n",
    "\n",
    "# Feature8: if the wrong productions in the last five actions occupied a large percentage. \n",
    "df2['wrongper'] = np.where(df2['howmanywrong-up'] == 0, \n",
    "                            0, \n",
    "                            (df2['recent5wrong'] / df2['howmanywrong-up']))\n",
    "# if 'recent5wrong' in df2.columns:\n",
    "#     df2['wrongper'] = np.where(df2['howmanywrong-up'] == 0, \n",
    "#                                 0, \n",
    "#                                 (df2[' recent5wrong'] / df2['howmanywrong-up']))\n",
    "# else:\n",
    "#     print(\"Column 'recent5wrong' does not exist!\")\n",
    "# merged8 = pd.merge(merged7,df2[['wrongper','Unique-id']], on='Unique-id', how='left')\n",
    "\n",
    "# Feature9: Calculate percentage of actions where the production was wrong in the overall number of notright\n",
    "df2['numerator'] = df2['howmanywrong-up']*merged5['totalstep']\n",
    "df2['percent_wrong'] = np.where(df2['notright'] == 0, \n",
    "                            0, \n",
    "                            (df2['numerator'] / df2['notright']))\n",
    "# merged9 = pd.merge(merged8,df2[['percent_wrong','Unique-id']], on='Unique-id', how='left')\n",
    "\n",
    "# Feature10: Calculate The total number of actions\n",
    "df2['ratio5'] = np.where(df2['Prev5Count-up'] == 0, \n",
    "                            0, \n",
    "                            (df2['recent5wrong'] / df2['Prev5Count-up']))\n",
    "# ca1_merged = pd.merge(merged9,df2[['ratio5','Unique-id']], on='Unique-id', how='left')\n",
    "\n",
    "\n",
    "\n",
    "# Merge all at once\n",
    "all_features = ['totalstep', 'totalaction', 'last5', 'wrongper', 'percent_wrong', 'ratio5', 'Unique-id']\n",
    "merged_all = pd.merge(merged1, df2[all_features], on='Unique-id', how='left')\n",
    "\n",
    "# print(df2.columns)\n",
    "\n",
    "# print(merged_all.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f92c81af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cohen's Kappa Score: 0.3116566258173174\n",
      "Mean ROC AUC: 0.617981981981982\n"
     ]
    }
   ],
   "source": [
    "#CA2\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    cohen_kappa_score,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset from a CSV file (replace 'ca1-dataset.csv' with your file path)\n",
    "dataset = pd.read_csv('ca1-dataset.csv')\n",
    "\n",
    "# Create a dictionary to store group information\n",
    "group_dict = {}\n",
    "groups = np.array([])\n",
    "\n",
    "# Iterate through the dataset to create groups\n",
    "for index, row in dataset.iterrows():\n",
    "    namea = row['Unique-id']\n",
    "    if namea not in group_dict:\n",
    "        group_dict[namea] = index\n",
    "    groups = np.append(groups, group_dict[namea])\n",
    "\n",
    "# Initialize the GroupKFold cross-validator\n",
    "group_kfold = GroupKFold(n_splits=10)\n",
    "\n",
    "# Define the target variable 'OffTask' and features (all columns except 'OffTask')\n",
    "X = dataset.drop(columns=['OffTask', 'Unique-id', 'namea'])  # Features\n",
    "y = dataset['OffTask']  # Target variable\n",
    "y = y.map({'N': 0, 'Y': 1})\n",
    "\n",
    "\n",
    "# Create lists to store evaluation metrics for each fold\n",
    "kappa_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score\n",
    "\n",
    "# # Define parameter grid\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.01, 0.1, 0.2], \n",
    "#     'n_estimators': [50, 100, 200], \n",
    "#     'max_depth': [5, 6, 7],  \n",
    "#     'alpha': [0.1, 1, 10],\n",
    "#     'lambda': [0.1, 1, 10]\n",
    "# }\n",
    "\n",
    "# # Initialize classifier\n",
    "# clf = xgb.XGBClassifier(\n",
    "#     objective='binary:logistic',\n",
    "#     eval_metric='error',\n",
    "#     use_label_encoder=False,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # Define custom scorer\n",
    "# kappa_scorer = make_scorer(cohen_kappa_score)\n",
    "\n",
    "# # Initialize GridSearchCV with custom scorer\n",
    "# grid_clf = GridSearchCV(clf, param_grid, scoring=kappa_scorer, cv=5, n_jobs=-1)\n",
    "\n",
    "# # Fit model\n",
    "# grid_clf.fit(X, y)  # Ensure your feature matrix X and target vector y are appropriately defined\n",
    "\n",
    "# # Get best parameters\n",
    "# best_params = grid_clf.best_params_\n",
    "# print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Initialize the parameters for the XGBClassifier\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'error',\n",
    "    'use_label_encoder': False,\n",
    "    'learning_rate': 0.2,  # Reduced learning rate\n",
    "    'n_estimators': 200,  # Increase n_estimators if you decrease learning rate\n",
    "    'random_state': 10,\n",
    "    'max_depth': 5,  # Limiting max_depth. You may want to optimize this using cross-validation\n",
    "    'alpha': 0.1,  # L1 regularization\n",
    "    'lambda': 1,  # L2 regularization\n",
    "}\n",
    "\n",
    "\n",
    "# Iterate through the folds\n",
    "for train_index, test_index in group_kfold.split(X, y, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "\n",
    "    # Create a DecisionTreeClassifier with specified hyperparameters\n",
    "    clf = xgb.XGBClassifier(**params)\n",
    "        # Use early stopping\n",
    "    eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "    clf.fit(X_train, y_train, eval_metric=\"error\", eval_set=eval_set, early_stopping_rounds=50, verbose=False)\n",
    "\n",
    "    # Use early stopping\n",
    "    eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "    clf.fit(X_train, y_train, eval_metric=\"error\", eval_set=eval_set, early_stopping_rounds=50, verbose=False)\n",
    "\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate Cohen's Kappa\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    kappa_scores.append(kappa)\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "\n",
    "# Calculate the mean values of the evaluation metrics across all folds\n",
    "mean_kappa_score = np.mean(kappa_scores)\n",
    "mean_roc_auc = np.mean(roc_auc_scores)\n",
    "\n",
    "print(\"Mean Cohen's Kappa Score:\", mean_kappa_score)\n",
    "print(\"Mean ROC AUC:\", mean_roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3b0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
